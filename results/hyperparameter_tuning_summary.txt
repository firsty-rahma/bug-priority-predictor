======================================================================
HYPERPARAMETER TUNING SUMMARY
======================================================================

Date: 2026-01-05 07:18:13
Dataset size: 9998 rows
Dev set: 7998 samples
Test set: 2000 samples

Label Encoding:
  blocker → 0
  critical → 1
  major → 2
  minor → 3
  normal → 4
  trivial → 5

----------------------------------------------------------------------
MODEL COMPARISON
----------------------------------------------------------------------

Random Forest:
  Best CV F1-Macro: 0.3350
  Tuning Time: 17.67 minutes
  Best Parameters:
    classifier__max_depth: 20
    classifier__min_samples_split: 10
    classifier__n_estimators: 200
    feature_combiner__ngram_range: (1, 1)

Logistic Regression:
  Best CV F1-Macro: 0.1053
  Tuning Time: 7.97 minutes
  Best Parameters:
    classifier__C: 1
    classifier__penalty: l2
    feature_combiner__ngram_range: (1, 2)

======================================================================
BEST MODEL: Random Forest
CV F1-Macro: 0.3350
======================================================================

TEST SET PERFORMANCE:
              precision    recall  f1-score   support

     blocker       0.22      0.05      0.08        41
    critical       0.48      0.49      0.49       121
       major       0.19      0.24      0.21       148
       minor       0.17      0.09      0.12       108
      normal       0.82      0.81      0.81      1521
     trivial       0.14      0.28      0.19        61

    accuracy                           0.68      2000
   macro avg       0.34      0.33      0.32      2000
weighted avg       0.68      0.68      0.68      2000
